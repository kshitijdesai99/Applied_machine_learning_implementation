{"metadata":{"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9709169,"sourceType":"datasetVersion","datasetId":5938550}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install torch torch-geometric pandas numpy scikit-learn","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:36:40.692225Z","iopub.execute_input":"2024-10-24T08:36:40.692663Z","iopub.status.idle":"2024-10-24T08:36:40.697737Z","shell.execute_reply.started":"2024-10-24T08:36:40.692621Z","shell.execute_reply":"2024-10-24T08:36:40.696831Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch_geometric\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GCNConv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:36:41.904056Z","iopub.execute_input":"2024-10-24T08:36:41.904589Z","iopub.status.idle":"2024-10-24T08:36:45.063776Z","shell.execute_reply.started":"2024-10-24T08:36:41.904550Z","shell.execute_reply":"2024-10-24T08:36:45.062975Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess data (reusing existing functions)\ndef load_and_preprocess_data(file_path, columns):\n    df = (pd.read_csv(file_path, usecols=columns)\n          .fillna(\"empty\")\n          .query(\"DevType != 'empty' and DevType != 'Other (please specify):'\")\n          .reset_index(drop=True))\n    return df\n\ndef combine_skills(df, columns, new_column_name):\n    df[new_column_name] = (df[columns]\n                           .fillna('')\n                           .agg(';'.join, axis=1)\n                           .apply(lambda x: x.split(';') if x else []))\n    return df\n\n# Load and preprocess data\ncolumns_finalized = ['ResponseId', 'DevType', 'LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith', 'PlatformHaveWorkedWith',\n                     'MiscTechHaveWorkedWith', 'WebframeHaveWorkedWith', 'DatabaseHaveWorkedWith']\n\ndf = load_and_preprocess_data(\"/kaggle/input/survey-results/survey_results_public.csv\", columns_finalized)\ndf = combine_skills(df, ['LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith', 'PlatformHaveWorkedWith',\n                         'MiscTechHaveWorkedWith', 'WebframeHaveWorkedWith', 'DatabaseHaveWorkedWith'], \n                    'AllSkillsHaveWorkedWith')\n\n# Filter out students\ndf_non_students = df.query(\"DevType != 'Student'\").reset_index(drop=True)\n\n# Prepare data for GNN\nskills = df_non_students['AllSkillsHaveWorkedWith'].explode().unique()\nskill_encoder = LabelEncoder().fit(skills)\ndev_type_encoder = LabelEncoder().fit(df_non_students['DevType'])\n\n# Define a fixed feature size\nfeature_size = 64\n\n# Create node features\nnum_users = len(df_non_students)\nnum_skills = len(skills)\nnum_dev_types = len(dev_type_encoder.classes_)\n\nuser_features = torch.randn(num_users, feature_size)\nskill_features = torch.randn(num_skills, feature_size)\ndev_type_features = torch.randn(num_dev_types, feature_size)\n\n\n# Create edges\nuser_skill_edges = []\nuser_dev_type_edges = []\n\nfor idx, row in df_non_students.iterrows():\n    user_skills = skill_encoder.transform(row['AllSkillsHaveWorkedWith'])\n    user_skill_edges.extend([(idx, skill_idx + num_users) for skill_idx in user_skills])\n    user_dev_type_edges.append((idx, dev_type_encoder.transform([row['DevType']])[0] + num_users + num_skills))\n\n# Combine all edges\nedges = user_skill_edges + user_dev_type_edges\nedge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n\n\n# Combine all node features\nx = torch.cat([user_features, skill_features, dev_type_features], dim=0)\n\n\n\n# Create PyTorch Geometric Data object\ndata = Data(x=x, edge_index=edge_index)\n\n# Define GNN model\n# class GNNJobRecommender(torch.nn.Module):\n#     def __init__(self, num_features, hidden_channels, num_classes):\n#         super(GNNJobRecommender, self).__init__()\n#         self.conv1 = GCNConv(num_features, hidden_channels)\n#         self.conv2 = GCNConv(hidden_channels, num_classes)\n\n#     def forward(self, x, edge_index):\n#         x = self.conv1(x, edge_index)\n#         x = x.relu()\n#         x = self.conv2(x, edge_index)\n#         return x\n\nfrom torch_geometric.nn import GATConv\n\nclass GNNJobRecommender(torch.nn.Module):\n    def __init__(self, num_features, hidden_channels, num_classes):\n        super(GNNJobRecommender, self).__init__()\n        # 8 attention heads in the first layer\n        self.conv1 = GATConv(num_features, hidden_channels, heads=8, dropout=0.6)\n        # 1 attention head in the second layer\n        self.conv2 = GATConv(hidden_channels * 8, num_classes, heads=1, concat=False, dropout=0.6)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = self.conv2(x, edge_index)\n        return x\n\n# Initialize model\nmodel = GNNJobRecommender(num_features=feature_size, hidden_channels=32, num_classes=num_dev_types)\n\n# Split data into train and test sets\ntrain_mask = torch.zeros(num_users, dtype=torch.bool)\ntrain_mask[:num_users-5000] = True\ntest_mask = ~train_mask\n\n# Prepare labels\ny = torch.tensor(dev_type_encoder.transform(df_non_students['DevType']))\n\n# Training function\ndef train(data, model, optimizer):\n    model.train()\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)\n    loss = torch.nn.functional.cross_entropy(out[:num_users][train_mask], y[train_mask])\n    loss.backward()\n    optimizer.step()\n    return loss\n\n# Evaluation function\ndef test(data, model):\n    model.eval()\n    out = model(data.x, data.edge_index)\n    pred = out[:num_users].argmax(dim=1)\n    test_correct = pred[test_mask] == y[test_mask]\n    test_acc = int(test_correct.sum()) / int(test_mask.sum())\n    return test_acc\n\n# Train the model\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nfor epoch in range(50):\n    loss = train(data, model, optimizer)\n    if epoch % 10 == 0:\n        test_acc = test(data, model)\n        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')\n\n# Function to get job recommendations\ndef get_job_recommendations(user_idx, model, data, dev_type_encoder, top_n=5):\n    model.eval()\n    with torch.no_grad():\n        out = model(data.x, data.edge_index)\n        user_probs = torch.nn.functional.softmax(out[user_idx], dim=0)\n        top_indices = user_probs.argsort(descending=True)[:top_n]\n        return dev_type_encoder.inverse_transform(top_indices.numpy())\n\n# Create a boolean mask for test users\ntest_mask_np = test_mask.numpy()\n\n# Example: Get top 5 job recommendations for a specific user in the test set\ntest_user_idx = np.where(test_mask_np)[0][0]\nrecommended_jobs = get_job_recommendations(test_user_idx, model, data, dev_type_encoder)\nprint(f\"Top job recommendations for user {test_user_idx}: {recommended_jobs}\")\n\n# Calculate MRR for test set\ndef calculate_mrr(true_jobs, predicted_jobs):\n    mrr = 0.0\n    for true_job, pred_jobs in zip(true_jobs, predicted_jobs):\n        try:\n            rank = np.where(pred_jobs == true_job)[0][0] + 1\n            mrr += 1 / rank\n        except IndexError:\n            continue\n    return mrr / len(true_jobs)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:37:34.757822Z","iopub.execute_input":"2024-10-24T08:37:34.758411Z","iopub.status.idle":"2024-10-24T08:41:37.188955Z","shell.execute_reply.started":"2024-10-24T08:37:34.758369Z","shell.execute_reply":"2024-10-24T08:41:37.187832Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch: 000, Loss: 4.4361, Test Acc: 0.1878\nEpoch: 010, Loss: 3.1584, Test Acc: 0.3372\nEpoch: 020, Loss: 2.9893, Test Acc: 0.3442\nEpoch: 030, Loss: 2.8965, Test Acc: 0.3434\nEpoch: 040, Loss: 2.8257, Test Acc: 0.3430\nTop job recommendations for user 46885: ['Developer, full-stack' 'Developer, back-end' 'Developer, front-end'\n 'Developer, desktop or enterprise applications' 'Developer, mobile']\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm  # Ensure you have tqdm for progress bar\n\n# Precompute the softmax probabilities for all users\ndef get_job_recommendations_batch(data, model):\n    model.eval()\n    with torch.no_grad():\n        out = model(data.x, data.edge_index)\n        softmax_out = torch.nn.functional.softmax(out[:num_users], dim=1)  # Precompute softmax for all users\n    return softmax_out\n\n# Precompute predictions for all users at once\nall_user_probs = get_job_recommendations_batch(data, model)\n\n# Get top N job recommendations for a specific user\ndef get_top_n_jobs(user_probs, dev_type_encoder, top_n=5):\n    top_indices = user_probs.argsort(descending=True)[:top_n]\n    return dev_type_encoder.inverse_transform(top_indices.numpy())\n\n# Precompute predicted jobs for all test users\ntrue_jobs_test = df_non_students.loc[test_mask_np, 'DevType'].values\ntest_user_indices = np.where(test_mask_np)[0]\npredicted_jobs_test = []\nfor user_idx in tqdm(test_user_indices):\n    user_probs = all_user_probs[user_idx]\n    recommended_jobs = get_top_n_jobs(user_probs, dev_type_encoder, top_n=10)\n    predicted_jobs_test.append(recommended_jobs)\n\n# Calculate MRR for the test set\nmrr_score_test = calculate_mrr(true_jobs_test, predicted_jobs_test)\nprint(f'MRR Score on Test Set: {mrr_score_test}')","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:41:37.191003Z","iopub.execute_input":"2024-10-24T08:41:37.191493Z","iopub.status.idle":"2024-10-24T08:41:39.996746Z","shell.execute_reply.started":"2024-10-24T08:41:37.191447Z","shell.execute_reply":"2024-10-24T08:41:39.995790Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 5000/5000 [00:00<00:00, 5268.69it/s]","output_type":"stream"},{"name":"stdout","text":"MRR Score on Test Set: 0.4969627777777765\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch_geometric\nfrom torch_geometric.data import HeteroData\nfrom torch_geometric.nn import HeteroConv, GCNConv, SAGEConv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\n\ndef load_and_preprocess_data(file_path, columns):\n    \"\"\"Load and preprocess the survey data.\"\"\"\n    df = pd.read_csv(file_path, usecols=columns)\n    # Convert string columns to lists if they're semicolon-separated\n    for col in columns:\n        if col not in ['ResponseId', 'DevType']:\n            df[col] = df[col].fillna('')\n    df = df.dropna(subset=['DevType'])  # Ensure DevType is not null\n    return df\n\ndef combine_skills(df, skill_columns, output_column):\n    \"\"\"Combine multiple skill columns into a single list.\"\"\"\n    def split_skills(x):\n        skills = []\n        for col in x:\n            if pd.notna(col) and col:\n                skills.extend([s.strip() for s in str(col).split(';') if s.strip()])\n        return skills\n\n    df[output_column] = df[skill_columns].apply(split_skills, axis=1)\n    return df\n\ndef prepare_heterogeneous_data(df_non_students, feature_size=64):\n    \"\"\"Prepare heterogeneous graph data.\"\"\"\n    # Handle empty skill lists\n    df_non_students = df_non_students[df_non_students['AllSkillsHaveWorkedWith'].apply(len) > 0].reset_index(drop=True)\n    \n    # Prepare encoders\n    all_skills = set()\n    for skills in df_non_students['AllSkillsHaveWorkedWith']:\n        all_skills.update(skills)\n    skills = np.array(list(all_skills))\n    \n    skill_encoder = LabelEncoder()\n    skill_encoder.fit(skills)\n    \n    dev_type_encoder = LabelEncoder()\n    dev_type_encoder.fit(df_non_students['DevType'])\n    \n    # Create HeteroData object\n    data = HeteroData()\n    \n    # Add node features\n    num_users = len(df_non_students)\n    num_skills = len(skills)\n    num_dev_types = len(dev_type_encoder.classes_)\n    \n    # Initialize features with normalization\n    data['user'].x = torch.nn.functional.normalize(torch.randn(num_users, feature_size), p=2, dim=1)\n    data['skill'].x = torch.nn.functional.normalize(torch.randn(num_skills, feature_size), p=2, dim=1)\n    data['dev_type'].x = torch.nn.functional.normalize(torch.randn(num_dev_types, feature_size), p=2, dim=1)\n    \n    # Create edges\n    user_skill_src = []\n    user_skill_dst = []\n    for idx, skills in enumerate(df_non_students['AllSkillsHaveWorkedWith']):\n        if skills:  # Check if skills list is not empty\n            skill_indices = skill_encoder.transform(skills)\n            user_skill_src.extend([idx] * len(skill_indices))\n            user_skill_dst.extend(skill_indices)\n    \n    dev_type_skill_src = []\n    dev_type_skill_dst = []\n    for dev_type_idx, dev_type in enumerate(dev_type_encoder.classes_):\n        dev_type_mask = df_non_students['DevType'] == dev_type\n        dev_type_users = df_non_students[dev_type_mask]\n        if not dev_type_users.empty:\n            dev_type_skills = []\n            for skills in dev_type_users['AllSkillsHaveWorkedWith']:\n                dev_type_skills.extend(skills)\n            if dev_type_skills:\n                skill_counts = pd.Series(dev_type_skills).value_counts()\n                top_skills = skill_counts.nlargest(min(10, len(skill_counts))).index\n                dev_type_skill_indices = skill_encoder.transform(top_skills)\n                dev_type_skill_src.extend([dev_type_idx] * len(dev_type_skill_indices))\n                dev_type_skill_dst.extend(dev_type_skill_indices)\n    \n    user_dev_type_src = list(range(len(df_non_students)))\n    user_dev_type_dst = dev_type_encoder.transform(df_non_students['DevType'])\n    \n    # Convert to tensors and add edges to data object\n    if user_skill_src:  # Only create edges if there are any\n        data['user', 'has_skill', 'skill'].edge_index = torch.tensor([user_skill_src, user_skill_dst])\n        data['skill', 'rev_has_skill', 'user'].edge_index = torch.tensor([user_skill_dst, user_skill_src])\n    \n    if dev_type_skill_src:  # Only create edges if there are any\n        data['dev_type', 'requires_skill', 'skill'].edge_index = torch.tensor([dev_type_skill_src, dev_type_skill_dst])\n        data['skill', 'rev_requires_skill', 'dev_type'].edge_index = torch.tensor([dev_type_skill_dst, dev_type_skill_src])\n    \n    data['user', 'has_type', 'dev_type'].edge_index = torch.tensor([user_dev_type_src, user_dev_type_dst])\n    data['dev_type', 'rev_has_type', 'user'].edge_index = torch.tensor([user_dev_type_dst, user_dev_type_src])\n    \n    return data, skill_encoder, dev_type_encoder, df_non_students\n\n# [Rest of the code remains the same until main]\n\nif __name__ == \"__main__\":\n    # Load and preprocess data\n    columns_finalized = ['ResponseId', 'DevType', 'LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith', \n                        'PlatformHaveWorkedWith', 'MiscTechHaveWorkedWith', 'WebframeHaveWorkedWith', \n                        'DatabaseHaveWorkedWith']\n    \n    df = load_and_preprocess_data(\"/kaggle/input/survey-results/survey_results_public.csv\", columns_finalized)\n    df = combine_skills(df, ['LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith', 'PlatformHaveWorkedWith',\n                            'MiscTechHaveWorkedWith', 'WebframeHaveWorkedWith', 'DatabaseHaveWorkedWith'], \n                       'AllSkillsHaveWorkedWith')\n    \n    # Filter out students and empty skills\n    df_non_students = df.query(\"DevType != 'Student'\").reset_index(drop=True)\n    \n    # Prepare data\n    data, skill_encoder, dev_type_encoder, df_non_students = prepare_heterogeneous_data(df_non_students)\n    \n    # Prepare masks\n    num_users = len(df_non_students)\n    indices = np.random.permutation(num_users)\n    train_idx = indices[:int(0.7*num_users)]\n    val_idx = indices[int(0.7*num_users):int(0.85*num_users)]\n    test_idx = indices[int(0.85*num_users):]\n    \n    train_mask = torch.zeros(num_users, dtype=torch.bool)\n    val_mask = torch.zeros(num_users, dtype=torch.bool)\n    test_mask = torch.zeros(num_users, dtype=torch.bool)\n    \n    train_mask[train_idx] = True\n    val_mask[val_idx] = True\n    test_mask[test_idx] = True\n    \n    # Prepare labels\n    y = torch.tensor(dev_type_encoder.transform(df_non_students['DevType'].values))\n    \n    # Initialize model\n    num_classes = len(dev_type_encoder.classes_)\n    model = ImprovedHGNNJobRecommender(hidden_channels=32, num_classes=num_classes)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    \n    # Train model\n    model = train_with_early_stopping(model, data, optimizer, num_users, train_mask, val_mask, y)\n    \n    # Get recommendations and evaluate\n    all_user_probs = get_job_recommendations_batch(model, data)\n    \n    # Evaluate on test set\n    test_mask_np = test_mask.numpy()\n    true_jobs_test = df_non_students.loc[test_mask_np, 'DevType'].values\n    test_user_indices = np.where(test_mask_np)[0]\n    \n    predicted_jobs_test = []\n    for user_idx in tqdm(test_user_indices, desc=\"Generating predictions\"):\n        user_probs = all_user_probs[user_idx]\n        recommended_jobs = get_top_n_jobs(user_probs, dev_type_encoder, top_n=10)\n        predicted_jobs_test.append(recommended_jobs)\n    \n    # Calculate and print MRR\n    mrr_score_test = calculate_mrr(true_jobs_test, predicted_jobs_test)\n    print(f'MRR Score on Test Set: {mrr_score_test}')\n    \n    # Print some example recommendations\n    print(\"\\nExample Recommendations:\")\n    for i in range(min(5, len(test_user_indices))):\n        user_idx = test_user_indices[i]\n        true_job = df_non_students.loc[user_idx, 'DevType']\n        recommendations = predicted_jobs_test[i]\n        print(f\"\\nUser {i+1}\")\n        print(f\"True Job: {true_job}\")\n        print(f\"Top 5 Recommendations: {', '.join(recommendations[:5])}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-24T09:15:40.688974Z","iopub.execute_input":"2024-10-24T09:15:40.689334Z","iopub.status.idle":"2024-10-24T09:16:59.042026Z","shell.execute_reply.started":"2024-10-24T09:15:40.689301Z","shell.execute_reply":"2024-10-24T09:16:59.040965Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch: 000, Loss: 3.3653, Val Acc: 0.1288\nEpoch: 010, Loss: 1.0860, Val Acc: 0.7757\nEpoch: 020, Loss: 0.6317, Val Acc: 0.8641\nEpoch: 030, Loss: 0.3855, Val Acc: 0.9098\nEpoch: 040, Loss: 0.2630, Val Acc: 0.9491\nEarly stopping at epoch 43\n","output_type":"stream"},{"name":"stderr","text":"Generating predictions: 100%|██████████| 7903/7903 [00:01<00:00, 4779.21it/s]","output_type":"stream"},{"name":"stdout","text":"MRR Score on Test Set: 0.959217566566042\n\nExample Recommendations:\n\nUser 1\nTrue Job: Developer, full-stack\nTop 5 Recommendations: Developer, full-stack, Developer, front-end, Designer, Data engineer, Educator\n\nUser 2\nTrue Job: Cloud infrastructure engineer\nTop 5 Recommendations: Cloud infrastructure engineer, Engineering manager, Developer, QA or test, Developer, embedded applications or devices, Data or business analyst\n\nUser 3\nTrue Job: Other (please specify):\nTop 5 Recommendations: Other (please specify):, Developer, desktop or enterprise applications, Developer, mobile, Developer, full-stack, Developer, embedded applications or devices\n\nUser 4\nTrue Job: Data scientist or machine learning specialist\nTop 5 Recommendations: Data scientist or machine learning specialist, Developer, mobile, Developer, front-end, Security professional, Developer, embedded applications or devices\n\nUser 5\nTrue Job: Developer, full-stack\nTop 5 Recommendations: Developer, full-stack, Developer, front-end, Designer, Educator, Developer, back-end\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def recommend_jobs_for_students(df, model, data, dev_type_encoder, skill_encoder, feature_size=64):\n    \"\"\"\n    Recommend jobs for students based on their skills using the trained model.\n    \n    Args:\n        df: Original DataFrame containing all data\n        model: Trained HGNNJobRecommender model\n        data: HeteroData object used for training\n        dev_type_encoder: Fitted LabelEncoder for dev types\n        skill_encoder: Fitted LabelEncoder for skills\n        feature_size: Size of feature vectors (default: 64)\n    \n    Returns:\n        DataFrame with student data and job recommendations\n    \"\"\"\n    # Filter students\n    df_students = df.query(\"DevType == 'Student'\").reset_index(drop=True)\n    \n    if len(df_students) == 0:\n        return df_students\n    \n    # Create feature vectors for students\n    num_students = len(df_students)\n    student_features = torch.nn.functional.normalize(torch.randn(num_students, feature_size), p=2, dim=1)\n    \n    # Create student-skill edges\n    student_skill_src = []\n    student_skill_dst = []\n    \n    for idx, skills in enumerate(df_students['AllSkillsHaveWorkedWith']):\n        if skills:  # Check if skills list is not empty\n            # Filter only known skills (those in the encoder)\n            known_skills = [skill for skill in skills if skill in skill_encoder.classes_]\n            if known_skills:\n                skill_indices = skill_encoder.transform(known_skills)\n                student_skill_src.extend([idx] * len(skill_indices))\n                student_skill_dst.extend(skill_indices)\n    \n    # Create temporary HeteroData object for students\n    student_data = HeteroData()\n    \n    # Copy existing skill and dev_type data\n    student_data['skill'].x = data['skill'].x\n    student_data['dev_type'].x = data['dev_type'].x\n    \n    # Add student features and edges\n    student_data['user'].x = student_features\n    \n    if student_skill_src:  # Only create edges if there are any\n        student_data['user', 'has_skill', 'skill'].edge_index = torch.tensor([student_skill_src, student_skill_dst])\n        student_data['skill', 'rev_has_skill', 'user'].edge_index = torch.tensor([student_skill_dst, student_skill_src])\n    \n    # Copy other relevant edges from training data\n    student_data['dev_type', 'requires_skill', 'skill'].edge_index = data['dev_type', 'requires_skill', 'skill'].edge_index\n    student_data['skill', 'rev_requires_skill', 'dev_type'].edge_index = data['skill', 'rev_requires_skill', 'dev_type'].edge_index\n    \n    # Get recommendations\n    model.eval()\n    with torch.no_grad():\n        all_student_probs = get_job_recommendations_batch(model, student_data)\n    \n    # Get top recommendations for each student\n    recommendations = []\n    recommendation_probs = []\n    for idx in range(len(df_students)):\n        student_probs = all_student_probs[idx]\n        # Get indices of top 5 probabilities\n        top_indices = torch.argsort(student_probs, descending=True)[:5]\n        # Get the actual probability values\n        top_probs = student_probs[top_indices].tolist()\n        # Get the job titles\n        top_jobs = [dev_type_encoder.inverse_transform([i.item()])[0] for i in top_indices]\n        \n        recommendations.append(top_jobs)\n        recommendation_probs.append(top_probs)\n    \n    # Add recommendations to DataFrame\n    df_students['RecommendedJobs'] = recommendations\n    df_students['RecommendationConfidence'] = recommendation_probs\n    \n    return df_students\n\n# Example usage after training the model:\ndef add_student_recommendations(df, model, data, dev_type_encoder, skill_encoder):\n    \"\"\"\n    Add job recommendations for students to the original DataFrame.\n    \"\"\"\n    # Get recommendations for students\n    df_students_with_recommendations = recommend_jobs_for_students(\n        df, model, data, dev_type_encoder, skill_encoder\n    )\n    \n    # Combine with non-student data\n    df_non_students = df.query(\"DevType != 'Student'\").reset_index(drop=True)\n    df_non_students['RecommendedJobs'] = None\n    df_non_students['RecommendationConfidence'] = None\n    \n    # Concatenate and sort by original index if needed\n    df_combined = pd.concat([df_non_students, df_students_with_recommendations], ignore_index=True)\n    \n    return df_combined\n\n# Usage in main:\nif __name__ == \"__main__\":    \n    # After training the model, add recommendations for students\n    df_with_recommendations = add_student_recommendations(\n        df, model, data, dev_type_encoder, skill_encoder\n    )\n    \n    # Example of printing recommendations for the first few students\n    print(\"\\nStudent Job Recommendations:\")\n    student_recommendations = df_with_recommendations[\n        df_with_recommendations['DevType'] == 'Student'\n    ][['RecommendedJobs', 'RecommendationConfidence']].head()\n    \n    for idx, row in student_recommendations.iterrows():\n        print(f\"\\nStudent {idx + 1}\")\n        for job, confidence in zip(row['RecommendedJobs'], row['RecommendationConfidence']):\n            print(f\"- {job}: {confidence:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:02:55.909115Z","iopub.execute_input":"2024-10-24T10:02:55.909512Z","iopub.status.idle":"2024-10-24T10:03:02.463571Z","shell.execute_reply.started":"2024-10-24T10:02:55.909478Z","shell.execute_reply":"2024-10-24T10:03:02.462636Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"\nStudent Job Recommendations:\n\nStudent 54344\n- Developer, full-stack: 0.115\n- Developer, back-end: 0.112\n- Engineering manager: 0.064\n- Developer, desktop or enterprise applications: 0.058\n- Developer, front-end: 0.056\n\nStudent 54345\n- Developer, full-stack: 0.191\n- Developer, front-end: 0.123\n- Developer, back-end: 0.104\n- Developer, desktop or enterprise applications: 0.051\n- Engineering manager: 0.042\n\nStudent 54346\n- Developer, front-end: 0.158\n- Developer, full-stack: 0.130\n- Developer, back-end: 0.114\n- Developer, desktop or enterprise applications: 0.056\n- Engineering manager: 0.046\n\nStudent 54347\n- Developer, full-stack: 0.132\n- Developer, back-end: 0.103\n- Engineering manager: 0.069\n- Developer, front-end: 0.064\n- Developer, desktop or enterprise applications: 0.062\n\nStudent 54348\n- Developer, full-stack: 0.134\n- Developer, back-end: 0.098\n- Developer, front-end: 0.061\n- Developer, desktop or enterprise applications: 0.056\n- Engineering manager: 0.052\n","output_type":"stream"}]},{"cell_type":"code","source":"df_with_recommendations[df_with_recommendations['DevType']=='Student']['RecommendedJobs'].apply(lambda x: x[0]).value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:05:09.295610Z","iopub.execute_input":"2024-10-24T10:05:09.296017Z","iopub.status.idle":"2024-10-24T10:05:09.320065Z","shell.execute_reply.started":"2024-10-24T10:05:09.295979Z","shell.execute_reply":"2024-10-24T10:05:09.319214Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"RecommendedJobs\nDeveloper, full-stack                            3720\nDeveloper, back-end                              1351\nDeveloper, front-end                               19\nDeveloper, desktop or enterprise applications      10\nDeveloper, embedded applications or devices         2\nName: count, dtype: int64"},"metadata":{}}]}]}