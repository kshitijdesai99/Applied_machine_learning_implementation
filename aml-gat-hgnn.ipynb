{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T08:36:40.692663Z","iopub.status.busy":"2024-10-24T08:36:40.692225Z","iopub.status.idle":"2024-10-24T08:36:40.697737Z","shell.execute_reply":"2024-10-24T08:36:40.696831Z","shell.execute_reply.started":"2024-10-24T08:36:40.692621Z"},"trusted":true},"outputs":[],"source":["# pip install torch torch-geometric pandas numpy scikit-learn"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T08:36:41.904589Z","iopub.status.busy":"2024-10-24T08:36:41.904056Z","iopub.status.idle":"2024-10-24T08:36:45.063776Z","shell.execute_reply":"2024-10-24T08:36:45.062975Z","shell.execute_reply.started":"2024-10-24T08:36:41.904550Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch_geometric\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GCNConv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T08:37:34.758411Z","iopub.status.busy":"2024-10-24T08:37:34.757822Z","iopub.status.idle":"2024-10-24T08:41:37.188955Z","shell.execute_reply":"2024-10-24T08:41:37.187832Z","shell.execute_reply.started":"2024-10-24T08:37:34.758369Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 000, Loss: 4.4361, Test Acc: 0.1878\n","Epoch: 010, Loss: 3.1584, Test Acc: 0.3372\n","Epoch: 020, Loss: 2.9893, Test Acc: 0.3442\n","Epoch: 030, Loss: 2.8965, Test Acc: 0.3434\n","Epoch: 040, Loss: 2.8257, Test Acc: 0.3430\n","Top job recommendations for user 46885: ['Developer, full-stack' 'Developer, back-end' 'Developer, front-end'\n"," 'Developer, desktop or enterprise applications' 'Developer, mobile']\n"]}],"source":["# Load and preprocess data (reusing existing functions)\n","def load_and_preprocess_data(file_path, columns):\n","    df = (pd.read_csv(file_path, usecols=columns)\n","          .fillna(\"empty\")\n","          .query(\"DevType != 'empty' and DevType != 'Other (please specify):'\")\n","          .reset_index(drop=True))\n","    return df\n","\n","def combine_skills(df, columns, new_column_name):\n","    df[new_column_name] = (df[columns]\n","                           .fillna('')\n","                           .agg(';'.join, axis=1)\n","                           .apply(lambda x: x.split(';') if x else []))\n","    return df\n","\n","# Load and preprocess data\n","columns_finalized = ['ResponseId', 'DevType', 'LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith', 'PlatformHaveWorkedWith',\n","                     'MiscTechHaveWorkedWith', 'WebframeHaveWorkedWith', 'DatabaseHaveWorkedWith']\n","\n","df = load_and_preprocess_data(\"/kaggle/input/survey-results/survey_results_public.csv\", columns_finalized)\n","df = combine_skills(df, ['LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith', 'PlatformHaveWorkedWith',\n","                         'MiscTechHaveWorkedWith', 'WebframeHaveWorkedWith', 'DatabaseHaveWorkedWith'], \n","                    'AllSkillsHaveWorkedWith')\n","\n","# Filter out students\n","df_non_students = df.query(\"DevType != 'Student'\").reset_index(drop=True)\n","\n","# Prepare data for GNN\n","skills = df_non_students['AllSkillsHaveWorkedWith'].explode().unique()\n","skill_encoder = LabelEncoder().fit(skills)\n","dev_type_encoder = LabelEncoder().fit(df_non_students['DevType'])\n","\n","# Define a fixed feature size\n","feature_size = 64\n","\n","# Create node features\n","num_users = len(df_non_students)\n","num_skills = len(skills)\n","num_dev_types = len(dev_type_encoder.classes_)\n","\n","user_features = torch.randn(num_users, feature_size)\n","skill_features = torch.randn(num_skills, feature_size)\n","dev_type_features = torch.randn(num_dev_types, feature_size)\n","\n","\n","# Create edges\n","user_skill_edges = []\n","user_dev_type_edges = []\n","\n","for idx, row in df_non_students.iterrows():\n","    user_skills = skill_encoder.transform(row['AllSkillsHaveWorkedWith'])\n","    user_skill_edges.extend([(idx, skill_idx + num_users) for skill_idx in user_skills])\n","    user_dev_type_edges.append((idx, dev_type_encoder.transform([row['DevType']])[0] + num_users + num_skills))\n","\n","# Combine all edges\n","edges = user_skill_edges + user_dev_type_edges\n","edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n","\n","\n","# Combine all node features\n","x = torch.cat([user_features, skill_features, dev_type_features], dim=0)\n","\n","\n","\n","# Create PyTorch Geometric Data object\n","data = Data(x=x, edge_index=edge_index)\n","\n","# Define GNN model\n","# class GNNJobRecommender(torch.nn.Module):\n","#     def __init__(self, num_features, hidden_channels, num_classes):\n","#         super(GNNJobRecommender, self).__init__()\n","#         self.conv1 = GCNConv(num_features, hidden_channels)\n","#         self.conv2 = GCNConv(hidden_channels, num_classes)\n","\n","#     def forward(self, x, edge_index):\n","#         x = self.conv1(x, edge_index)\n","#         x = x.relu()\n","#         x = self.conv2(x, edge_index)\n","#         return x\n","\n","from torch_geometric.nn import GATConv\n","\n","class GNNJobRecommender(torch.nn.Module):\n","    def __init__(self, num_features, hidden_channels, num_classes):\n","        super(GNNJobRecommender, self).__init__()\n","        # 8 attention heads in the first layer\n","        self.conv1 = GATConv(num_features, hidden_channels, heads=8, dropout=0.6)\n","        # 1 attention head in the second layer\n","        self.conv2 = GATConv(hidden_channels * 8, num_classes, heads=1, concat=False, dropout=0.6)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = x.relu()\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","# Initialize model\n","model = GNNJobRecommender(num_features=feature_size, hidden_channels=32, num_classes=num_dev_types)\n","\n","# Split data into train and test sets\n","train_mask = torch.zeros(num_users, dtype=torch.bool)\n","train_mask[:num_users-5000] = True\n","test_mask = ~train_mask\n","\n","# Prepare labels\n","y = torch.tensor(dev_type_encoder.transform(df_non_students['DevType']))\n","\n","# Training function\n","def train(data, model, optimizer):\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data.x, data.edge_index)\n","    loss = torch.nn.functional.cross_entropy(out[:num_users][train_mask], y[train_mask])\n","    loss.backward()\n","    optimizer.step()\n","    return loss\n","\n","# Evaluation function\n","def test(data, model):\n","    model.eval()\n","    out = model(data.x, data.edge_index)\n","    pred = out[:num_users].argmax(dim=1)\n","    test_correct = pred[test_mask] == y[test_mask]\n","    test_acc = int(test_correct.sum()) / int(test_mask.sum())\n","    return test_acc\n","\n","# Train the model\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","for epoch in range(50):\n","    loss = train(data, model, optimizer)\n","    if epoch % 10 == 0:\n","        test_acc = test(data, model)\n","        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')\n","\n","# Function to get job recommendations\n","def get_job_recommendations(user_idx, model, data, dev_type_encoder, top_n=5):\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data.x, data.edge_index)\n","        user_probs = torch.nn.functional.softmax(out[user_idx], dim=0)\n","        top_indices = user_probs.argsort(descending=True)[:top_n]\n","        return dev_type_encoder.inverse_transform(top_indices.numpy())\n","\n","# Create a boolean mask for test users\n","test_mask_np = test_mask.numpy()\n","\n","# Example: Get top 5 job recommendations for a specific user in the test set\n","test_user_idx = np.where(test_mask_np)[0][0]\n","recommended_jobs = get_job_recommendations(test_user_idx, model, data, dev_type_encoder)\n","print(f\"Top job recommendations for user {test_user_idx}: {recommended_jobs}\")\n","\n","# Calculate MRR for test set\n","def calculate_mrr(true_jobs, predicted_jobs):\n","    mrr = 0.0\n","    for true_job, pred_jobs in zip(true_jobs, predicted_jobs):\n","        try:\n","            rank = np.where(pred_jobs == true_job)[0][0] + 1\n","            mrr += 1 / rank\n","        except IndexError:\n","            continue\n","    return mrr / len(true_jobs)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T08:41:37.191493Z","iopub.status.busy":"2024-10-24T08:41:37.191003Z","iopub.status.idle":"2024-10-24T08:41:39.996746Z","shell.execute_reply":"2024-10-24T08:41:39.995790Z","shell.execute_reply.started":"2024-10-24T08:41:37.191447Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5000/5000 [00:00<00:00, 5268.69it/s]"]},{"name":"stdout","output_type":"stream","text":["MRR Score on Test Set: 0.4969627777777765\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from tqdm import tqdm  # Ensure you have tqdm for progress bar\n","\n","# Precompute the softmax probabilities for all users\n","def get_job_recommendations_batch(data, model):\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data.x, data.edge_index)\n","        softmax_out = torch.nn.functional.softmax(out[:num_users], dim=1)  # Precompute softmax for all users\n","    return softmax_out\n","\n","# Precompute predictions for all users at once\n","all_user_probs = get_job_recommendations_batch(data, model)\n","\n","# Get top N job recommendations for a specific user\n","def get_top_n_jobs(user_probs, dev_type_encoder, top_n=5):\n","    top_indices = user_probs.argsort(descending=True)[:top_n]\n","    return dev_type_encoder.inverse_transform(top_indices.numpy())\n","\n","# Precompute predicted jobs for all test users\n","true_jobs_test = df_non_students.loc[test_mask_np, 'DevType'].values\n","test_user_indices = np.where(test_mask_np)[0]\n","predicted_jobs_test = []\n","for user_idx in tqdm(test_user_indices):\n","    user_probs = all_user_probs[user_idx]\n","    recommended_jobs = get_top_n_jobs(user_probs, dev_type_encoder, top_n=10)\n","    predicted_jobs_test.append(recommended_jobs)\n","\n","# Calculate MRR for the test set\n","mrr_score_test = calculate_mrr(true_jobs_test, predicted_jobs_test)\n","print(f'MRR Score on Test Set: {mrr_score_test}')"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T09:15:40.689334Z","iopub.status.busy":"2024-10-24T09:15:40.688974Z","iopub.status.idle":"2024-10-24T09:16:59.042026Z","shell.execute_reply":"2024-10-24T09:16:59.040965Z","shell.execute_reply.started":"2024-10-24T09:15:40.689301Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 000, Loss: 3.3653, Val Acc: 0.1288\n","Epoch: 010, Loss: 1.0860, Val Acc: 0.7757\n","Epoch: 020, Loss: 0.6317, Val Acc: 0.8641\n","Epoch: 030, Loss: 0.3855, Val Acc: 0.9098\n","Epoch: 040, Loss: 0.2630, Val Acc: 0.9491\n","Early stopping at epoch 43\n"]},{"name":"stderr","output_type":"stream","text":["Generating predictions: 100%|██████████| 7903/7903 [00:01<00:00, 4779.21it/s]"]},{"name":"stdout","output_type":"stream","text":["MRR Score on Test Set: 0.959217566566042\n","\n","Example Recommendations:\n","\n","User 1\n","True Job: Developer, full-stack\n","Top 5 Recommendations: Developer, full-stack, Developer, front-end, Designer, Data engineer, Educator\n","\n","User 2\n","True Job: Cloud infrastructure engineer\n","Top 5 Recommendations: Cloud infrastructure engineer, Engineering manager, Developer, QA or test, Developer, embedded applications or devices, Data or business analyst\n","\n","User 3\n","True Job: Other (please specify):\n","Top 5 Recommendations: Other (please specify):, Developer, desktop or enterprise applications, Developer, mobile, Developer, full-stack, Developer, embedded applications or devices\n","\n","User 4\n","True Job: Data scientist or machine learning specialist\n","Top 5 Recommendations: Data scientist or machine learning specialist, Developer, mobile, Developer, front-end, Security professional, Developer, embedded applications or devices\n","\n","User 5\n","True Job: Developer, full-stack\n","Top 5 Recommendations: Developer, full-stack, Developer, front-end, Designer, Educator, Developer, back-end\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch_geometric\n","from torch_geometric.data import HeteroData\n","from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm import tqdm\n","import torch\n","import torch.nn.functional as F\n","\n","def load_and_preprocess_data(file_path, columns):\n","    \"\"\"Load and preprocess the survey data.\"\"\"\n","    df = pd.read_csv(file_path, usecols=columns)\n","    # Convert string columns to lists if they're semicolon-separated\n","    for col in columns:\n","        if col not in ['ResponseId', 'DevType']:\n","            df[col] = df[col].fillna('')\n","    df = df.dropna(subset=['DevType'])  # Ensure DevType is not null\n","    return df\n","\n","def combine_skills(df, skill_columns, output_column):\n","    \"\"\"Combine multiple skill columns into a single list.\"\"\"\n","    def split_skills(x):\n","        skills = []\n","        for col in x:\n","            if pd.notna(col) and col:\n","                skills.extend([s.strip() for s in str(col).split(';') if s.strip()])\n","        return skills\n","\n","    df[output_column] = df[skill_columns].apply(split_skills, axis=1)\n","    return df\n","\n","def prepare_heterogeneous_data(df_non_students, feature_size=64):\n","    \"\"\"Prepare heterogeneous graph data.\"\"\"\n","    # Handle empty skill lists\n","    df_non_students = df_non_students[df_non_students['AllSkillsHaveWorkedWith'].apply(len) > 0].reset_index(drop=True)\n","    \n","    # Prepare encoders\n","    all_skills = set()\n","    for skills in df_non_students['AllSkillsHaveWorkedWith']:\n","        all_skills.update(skills)\n","    skills = np.array(list(all_skills))\n","    \n","    skill_encoder = LabelEncoder()\n","    skill_encoder.fit(skills)\n","    \n","    dev_type_encoder = LabelEncoder()\n","    dev_type_encoder.fit(df_non_students['DevType'])\n","    \n","    # Create HeteroData object\n","    data = HeteroData()\n","    \n","    # Add node features\n","    num_users = len(df_non_students)\n","    num_skills = len(skills)\n","    num_dev_types = len(dev_type_encoder.classes_)\n","    \n","    # Initialize features with normalization\n","    data['user'].x = torch.nn.functional.normalize(torch.randn(num_users, feature_size), p=2, dim=1)\n","    data['skill'].x = torch.nn.functional.normalize(torch.randn(num_skills, feature_size), p=2, dim=1)\n","    data['dev_type'].x = torch.nn.functional.normalize(torch.randn(num_dev_types, feature_size), p=2, dim=1)\n","    \n","    # Create edges\n","    user_skill_src = []\n","    user_skill_dst = []\n","    for idx, skills in enumerate(df_non_students['AllSkillsHaveWorkedWith']):\n","        if skills:  # Check if skills list is not empty\n","            skill_indices = skill_encoder.transform(skills)\n","            user_skill_src.extend([idx] * len(skill_indices))\n","            user_skill_dst.extend(skill_indices)\n","    \n","    dev_type_skill_src = []\n","    dev_type_skill_dst = []\n","    for dev_type_idx, dev_type in enumerate(dev_type_encoder.classes_):\n","        dev_type_mask = df_non_students['DevType'] == dev_type\n","        dev_type_users = df_non_students[dev_type_mask]\n","        if not dev_type_users.empty:\n","            dev_type_skills = []\n","            for skills in dev_type_users['AllSkillsHaveWorkedWith']:\n","                dev_type_skills.extend(skills)\n","            if dev_type_skills:\n","                skill_counts = pd.Series(dev_type_skills).value_counts()\n","                top_skills = skill_counts.nlargest(min(10, len(skill_counts))).index\n","                dev_type_skill_indices = skill_encoder.transform(top_skills)\n","                dev_type_skill_src.extend([dev_type_idx] * len(dev_type_skill_indices))\n","                dev_type_skill_dst.extend(dev_type_skill_indices)\n","    \n","    user_dev_type_src = list(range(len(df_non_students)))\n","    user_dev_type_dst = dev_type_encoder.transform(df_non_students['DevType'])\n","    \n","    # Convert to tensors and add edges to data object\n","    if user_skill_src:  # Only create edges if there are any\n","        data['user', 'has_skill', 'skill'].edge_index = torch.tensor([user_skill_src, user_skill_dst])\n","        data['skill', 'rev_has_skill', 'user'].edge_index = torch.tensor([user_skill_dst, user_skill_src])\n","    \n","    if dev_type_skill_src:  # Only create edges if there are any\n","        data['dev_type', 'requires_skill', 'skill'].edge_index = torch.tensor([dev_type_skill_src, dev_type_skill_dst])\n","        data['skill', 'rev_requires_skill', 'dev_type'].edge_index = torch.tensor([dev_type_skill_dst, dev_type_skill_src])\n","    \n","    data['user', 'has_type', 'dev_type'].edge_index = torch.tensor([user_dev_type_src, user_dev_type_dst])\n","    data['dev_type', 'rev_has_type', 'user'].edge_index = torch.tensor([user_dev_type_dst, user_dev_type_src])\n","    \n","    return data, skill_encoder, dev_type_encoder, df_non_students\n","\n","class ImprovedHGNNJobRecommender(torch.nn.Module):\n","    def __init__(self, hidden_channels, num_classes):\n","        super(ImprovedHGNNJobRecommender, self).__init__()\n","        \n","        self.conv1 = HeteroConv({\n","            ('user', 'has_skill', 'skill'): GCNConv(-1, hidden_channels),\n","            ('skill', 'rev_has_skill', 'user'): GCNConv(-1, hidden_channels),\n","            ('dev_type', 'requires_skill', 'skill'): GCNConv(-1, hidden_channels),\n","            ('skill', 'rev_requires_skill', 'dev_type'): GCNConv(-1, hidden_channels),\n","            ('user', 'has_type', 'dev_type'): GCNConv(-1, hidden_channels),\n","            ('dev_type', 'rev_has_type', 'user'): GCNConv(-1, hidden_channels),\n","        }, aggr='mean')\n","\n","        self.conv2 = HeteroConv({\n","            ('user', 'has_skill', 'skill'): GCNConv(hidden_channels, hidden_channels),\n","            ('skill', 'rev_has_skill', 'user'): GCNConv(hidden_channels, hidden_channels),\n","            ('dev_type', 'requires_skill', 'skill'): GCNConv(hidden_channels, hidden_channels),\n","            ('skill', 'rev_requires_skill', 'dev_type'): GCNConv(hidden_channels, hidden_channels),\n","            ('user', 'has_type', 'dev_type'): GCNConv(hidden_channels, hidden_channels),\n","            ('dev_type', 'rev_has_type', 'user'): GCNConv(hidden_channels, hidden_channels),\n","        }, aggr='mean')\n","        \n","        self.lin = torch.nn.Linear(hidden_channels, num_classes)\n","\n","    def forward(self, data):\n","        x_dict, edge_index_dict = data.x_dict, data.edge_index_dict\n","        \n","        # First convolution layer\n","        x_dict = self.conv1(x_dict, edge_index_dict)\n","        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n","        \n","        # Second convolution layer\n","        x_dict = self.conv2(x_dict, edge_index_dict)\n","        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n","        \n","        # Final layer for classification\n","        return self.lin(x_dict['user'])\n","\n","def get_job_recommendations_batch(model, data):\n","    \"\"\"Get job recommendations for all users in batch.\"\"\"\n","    model.eval()\n","    with torch.no_grad():\n","        logits = model(data)\n","        return F.softmax(logits, dim=1).numpy()\n","\n","def get_top_n_jobs(user_probs, dev_type_encoder, top_n=10):\n","    \"\"\"Get top N job recommendations for a user.\"\"\"\n","    top_indices = np.argsort(user_probs)[-top_n:][::-1]\n","    return dev_type_encoder.inverse_transform(top_indices)\n","\n","def calculate_mrr(true_jobs, predicted_jobs):\n","    \"\"\"Calculate Mean Reciprocal Rank.\"\"\"\n","    reciprocal_ranks = []\n","    for true_job, predictions in zip(true_jobs, predicted_jobs):\n","        try:\n","            rank = predictions.tolist().index(true_job) + 1\n","            reciprocal_ranks.append(1.0 / rank)\n","        except ValueError:\n","            reciprocal_ranks.append(0.0)\n","    return np.mean(reciprocal_ranks)\n","\n","def train_with_early_stopping(model, data, optimizer, num_users, train_mask, val_mask, labels, \n","                            patience=5, epochs=100, batch_size=32):\n","    \"\"\"\n","    Train the GNN model with early stopping based on validation loss.\n","    \n","    Parameters:\n","    - model: The GNN model to be trained\n","    - data: HeteroData object containing the graph\n","    - optimizer: PyTorch optimizer\n","    - num_users: Total number of users\n","    - train_mask: Boolean mask for training samples\n","    - val_mask: Boolean mask for validation samples\n","    - labels: Ground truth labels\n","    - patience: Number of epochs to wait before early stopping\n","    - epochs: Maximum number of training epochs\n","    - batch_size: Batch size for training\n","    \n","    Returns:\n","    - Trained model\n","    \"\"\"\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","    data = data.to(device)\n","    labels = labels.to(device)\n","    \n","    best_val_loss = float('inf')\n","    best_model_state = None\n","    patience_counter = 0\n","    train_losses = []\n","    val_losses = []\n","    \n","    # Get indices for training and validation\n","    train_indices = torch.where(train_mask)[0]\n","    val_indices = torch.where(val_mask)[0]\n","    \n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss = 0\n","        num_batches = 0\n","        \n","        # Training\n","        for i in range(0, len(train_indices), batch_size):\n","            batch_indices = train_indices[i:i + batch_size]\n","            \n","            # Zero gradients\n","            optimizer.zero_grad()\n","            \n","            # Forward pass\n","            out = model(data)\n","            batch_out = out[batch_indices]\n","            batch_labels = labels[batch_indices]\n","            \n","            # Calculate loss\n","            loss = F.cross_entropy(batch_out, batch_labels)\n","            \n","            # Backward pass\n","            loss.backward()\n","            optimizer.step()\n","            \n","            total_train_loss += loss.item()\n","            num_batches += 1\n","        \n","        avg_train_loss = total_train_loss / num_batches\n","        train_losses.append(avg_train_loss)\n","        \n","        # Validation\n","        model.eval()\n","        total_val_loss = 0\n","        val_correct = 0\n","        val_total = 0\n","        \n","        with torch.no_grad():\n","            # Forward pass on validation set\n","            val_out = model(data)\n","            val_batch_out = val_out[val_indices]\n","            val_batch_labels = labels[val_indices]\n","            \n","            # Calculate validation loss\n","            val_loss = F.cross_entropy(val_batch_out, val_batch_labels)\n","            total_val_loss = val_loss.item()\n","            \n","            # Calculate validation accuracy\n","            _, predicted = torch.max(val_batch_out, 1)\n","            val_correct = (predicted == val_batch_labels).sum().item()\n","            val_total = len(val_indices)\n","        \n","        avg_val_loss = total_val_loss\n","        val_accuracy = val_correct / val_total\n","        val_losses.append(avg_val_loss)\n","        \n","        # Print epoch statistics\n","        print(f'Epoch [{epoch+1}/{epochs}]')\n","        print(f'Training Loss: {avg_train_loss:.4f}')\n","        print(f'Validation Loss: {avg_val_loss:.4f}')\n","        print(f'Validation Accuracy: {val_accuracy:.4f}')\n","        print('-' * 50)\n","        \n","        # Early stopping check\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            best_model_state = model.state_dict()\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            \n","        # Early stopping trigger\n","        if patience_counter >= patience:\n","            print(f'Early stopping triggered after {epoch + 1} epochs')\n","            break\n","    \n","    # Load best model state\n","    if best_model_state is not None:\n","        model.load_state_dict(best_model_state)\n","    \n","    return model\n","\n","def train_epoch(model, data, optimizer, train_indices, labels, batch_size):\n","    \"\"\"Helper function to train one epoch\"\"\"\n","    model.train()\n","    total_loss = 0\n","    num_batches = 0\n","    \n","    # Create batches\n","    for i in range(0, len(train_indices), batch_size):\n","        batch_indices = train_indices[i:i + batch_size]\n","        \n","        # Zero gradients\n","        optimizer.zero_grad()\n","        \n","        # Forward pass\n","        out = model(data)\n","        batch_out = out[batch_indices]\n","        batch_labels = labels[batch_indices]\n","        \n","        # Calculate loss\n","        loss = F.cross_entropy(batch_out, batch_labels)\n","        \n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","        \n","        total_loss += loss.item()\n","        num_batches += 1\n","    \n","    return total_loss / num_batches\n","\n","def evaluate(model, data, indices, labels):\n","    \"\"\"Helper function to evaluate the model\"\"\"\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data)\n","        batch_out = out[indices]\n","        batch_labels = labels[indices]\n","        \n","        # Calculate loss\n","        loss = F.cross_entropy(batch_out, batch_labels)\n","        \n","        # Calculate accuracy\n","        _, predicted = torch.max(batch_out, 1)\n","        correct = (predicted == batch_labels).sum().item()\n","        total = len(indices)\n","        \n","    return loss.item(), correct / total\n","\n","if __name__ == \"__main__\":\n","    # Load and preprocess data\n","    columns_finalized = ['ResponseId', 'DevType', 'LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith', \n","                        'PlatformHaveWorkedWith', 'MiscTechHaveWorkedWith', 'WebframeHaveWorkedWith', \n","                        'DatabaseHaveWorkedWith']\n","    \n","    df = load_and_preprocess_data(\"survey_results_public.csv\", columns_finalized)\n","    df = combine_skills(df, ['LanguageHaveWorkedWith', 'ToolsTechHaveWorkedWith', 'PlatformHaveWorkedWith',\n","                            'MiscTechHaveWorkedWith', 'WebframeHaveWorkedWith', 'DatabaseHaveWorkedWith'], \n","                       'AllSkillsHaveWorkedWith')\n","    \n","    # Filter out students and empty skills\n","    df_non_students = df.query(\"DevType != 'Student'\").reset_index(drop=True)\n","    \n","    # Prepare data\n","    data, skill_encoder, dev_type_encoder, df_non_students = prepare_heterogeneous_data(df_non_students)\n","    \n","    # Prepare masks\n","    num_users = len(df_non_students)\n","    indices = np.random.permutation(num_users)\n","    train_idx = indices[:int(0.7*num_users)]\n","    val_idx = indices[int(0.7*num_users):int(0.85*num_users)]\n","    test_idx = indices[int(0.85*num_users):]\n","    \n","    train_mask = torch.zeros(num_users, dtype=torch.bool)\n","    val_mask = torch.zeros(num_users, dtype=torch.bool)\n","    test_mask = torch.zeros(num_users, dtype=torch.bool)\n","    \n","    train_mask[train_idx] = True\n","    val_mask[val_idx] = True\n","    test_mask[test_idx] = True\n","    \n","    # Prepare labels\n","    y = torch.tensor(dev_type_encoder.transform(df_non_students['DevType'].values))\n","    \n","    # Initialize model\n","    num_classes = len(dev_type_encoder.classes_)\n","    model = ImprovedHGNNJobRecommender(hidden_channels=32, num_classes=num_classes)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","    \n","    # Train model\n","    model = train_with_early_stopping(model, data, optimizer, num_users, train_mask, val_mask, y)\n","    \n","    # Get recommendations and evaluate\n","    all_user_probs = get_job_recommendations_batch(model, data)\n","    \n","    # Evaluate on test set\n","    test_mask_np = test_mask.numpy()\n","    true_jobs_test = df_non_students.loc[test_mask_np, 'DevType'].values\n","    test_user_indices = np.where(test_mask_np)[0]\n","    \n","    predicted_jobs_test = []\n","    for user_idx in tqdm(test_user_indices, desc=\"Generating predictions\"):\n","        user_probs = all_user_probs[user_idx]\n","        recommended_jobs = get_top_n_jobs(user_probs, dev_type_encoder, top_n=10)\n","        predicted_jobs_test.append(recommended_jobs)\n","    \n","    # Calculate and print MRR\n","    mrr_score_test = calculate_mrr(true_jobs_test, predicted_jobs_test)\n","    print(f'MRR Score on Test Set: {mrr_score_test}')\n","    \n","    # Print some example recommendations\n","    print(\"\\nExample Recommendations:\")\n","    for i in range(min(5, len(test_user_indices))):\n","        user_idx = test_user_indices[i]\n","        true_job = df_non_students.loc[user_idx, 'DevType']\n","        recommendations = predicted_jobs_test[i]\n","        print(f\"\\nUser {i+1}\")\n","        print(f\"True Job: {true_job}\")\n","        print(f\"Top 5 Recommendations: {', '.join(recommendations[:5])}\")"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:02:55.909512Z","iopub.status.busy":"2024-10-24T10:02:55.909115Z","iopub.status.idle":"2024-10-24T10:03:02.463571Z","shell.execute_reply":"2024-10-24T10:03:02.462636Z","shell.execute_reply.started":"2024-10-24T10:02:55.909478Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Student Job Recommendations:\n","\n","Student 54344\n","- Developer, full-stack: 0.115\n","- Developer, back-end: 0.112\n","- Engineering manager: 0.064\n","- Developer, desktop or enterprise applications: 0.058\n","- Developer, front-end: 0.056\n","\n","Student 54345\n","- Developer, full-stack: 0.191\n","- Developer, front-end: 0.123\n","- Developer, back-end: 0.104\n","- Developer, desktop or enterprise applications: 0.051\n","- Engineering manager: 0.042\n","\n","Student 54346\n","- Developer, front-end: 0.158\n","- Developer, full-stack: 0.130\n","- Developer, back-end: 0.114\n","- Developer, desktop or enterprise applications: 0.056\n","- Engineering manager: 0.046\n","\n","Student 54347\n","- Developer, full-stack: 0.132\n","- Developer, back-end: 0.103\n","- Engineering manager: 0.069\n","- Developer, front-end: 0.064\n","- Developer, desktop or enterprise applications: 0.062\n","\n","Student 54348\n","- Developer, full-stack: 0.134\n","- Developer, back-end: 0.098\n","- Developer, front-end: 0.061\n","- Developer, desktop or enterprise applications: 0.056\n","- Engineering manager: 0.052\n"]}],"source":["def recommend_jobs_for_students(df, model, data, dev_type_encoder, skill_encoder, feature_size=64):\n","    \"\"\"\n","    Recommend jobs for students based on their skills using the trained model.\n","    \n","    Args:\n","        df: Original DataFrame containing all data\n","        model: Trained HGNNJobRecommender model\n","        data: HeteroData object used for training\n","        dev_type_encoder: Fitted LabelEncoder for dev types\n","        skill_encoder: Fitted LabelEncoder for skills\n","        feature_size: Size of feature vectors (default: 64)\n","    \n","    Returns:\n","        DataFrame with student data and job recommendations\n","    \"\"\"\n","    # Filter students\n","    df_students = df.query(\"DevType == 'Student'\").reset_index(drop=True)\n","    \n","    if len(df_students) == 0:\n","        return df_students\n","    \n","    # Create feature vectors for students\n","    num_students = len(df_students)\n","    student_features = torch.nn.functional.normalize(torch.randn(num_students, feature_size), p=2, dim=1)\n","    \n","    # Create student-skill edges\n","    student_skill_src = []\n","    student_skill_dst = []\n","    \n","    for idx, skills in enumerate(df_students['AllSkillsHaveWorkedWith']):\n","        if skills:  # Check if skills list is not empty\n","            # Filter only known skills (those in the encoder)\n","            known_skills = [skill for skill in skills if skill in skill_encoder.classes_]\n","            if known_skills:\n","                skill_indices = skill_encoder.transform(known_skills)\n","                student_skill_src.extend([idx] * len(skill_indices))\n","                student_skill_dst.extend(skill_indices)\n","    \n","    # Create temporary HeteroData object for students\n","    student_data = HeteroData()\n","    \n","    # Copy existing skill and dev_type data\n","    student_data['skill'].x = data['skill'].x\n","    student_data['dev_type'].x = data['dev_type'].x\n","    \n","    # Add student features and edges\n","    student_data['user'].x = student_features\n","    \n","    if student_skill_src:  # Only create edges if there are any\n","        student_data['user', 'has_skill', 'skill'].edge_index = torch.tensor([student_skill_src, student_skill_dst])\n","        student_data['skill', 'rev_has_skill', 'user'].edge_index = torch.tensor([student_skill_dst, student_skill_src])\n","    \n","    # Copy other relevant edges from training data\n","    student_data['dev_type', 'requires_skill', 'skill'].edge_index = data['dev_type', 'requires_skill', 'skill'].edge_index\n","    student_data['skill', 'rev_requires_skill', 'dev_type'].edge_index = data['skill', 'rev_requires_skill', 'dev_type'].edge_index\n","    \n","    # Get recommendations\n","    model.eval()\n","    with torch.no_grad():\n","        all_student_probs = get_job_recommendations_batch(model, student_data)\n","    \n","    # Get top recommendations for each student\n","    recommendations = []\n","    recommendation_probs = []\n","    for idx in range(len(df_students)):\n","        student_probs = all_student_probs[idx]\n","        # Get indices of top 5 probabilities\n","        top_indices = torch.argsort(student_probs, descending=True)[:5]\n","        # Get the actual probability values\n","        top_probs = student_probs[top_indices].tolist()\n","        # Get the job titles\n","        top_jobs = [dev_type_encoder.inverse_transform([i.item()])[0] for i in top_indices]\n","        \n","        recommendations.append(top_jobs)\n","        recommendation_probs.append(top_probs)\n","    \n","    # Add recommendations to DataFrame\n","    df_students['RecommendedJobs'] = recommendations\n","    df_students['RecommendationConfidence'] = recommendation_probs\n","    \n","    return df_students\n","\n","# Example usage after training the model:\n","def add_student_recommendations(df, model, data, dev_type_encoder, skill_encoder):\n","    \"\"\"\n","    Add job recommendations for students to the original DataFrame.\n","    \"\"\"\n","    # Get recommendations for students\n","    df_students_with_recommendations = recommend_jobs_for_students(\n","        df, model, data, dev_type_encoder, skill_encoder\n","    )\n","    \n","    # Combine with non-student data\n","    df_non_students = df.query(\"DevType != 'Student'\").reset_index(drop=True)\n","    df_non_students['RecommendedJobs'] = None\n","    df_non_students['RecommendationConfidence'] = None\n","    \n","    # Concatenate and sort by original index if needed\n","    df_combined = pd.concat([df_non_students, df_students_with_recommendations], ignore_index=True)\n","    \n","    return df_combined\n","\n","# Usage in main:\n","if __name__ == \"__main__\":    \n","    # After training the model, add recommendations for students\n","    df_with_recommendations = add_student_recommendations(\n","        df, model, data, dev_type_encoder, skill_encoder\n","    )\n","    \n","    # Example of printing recommendations for the first few students\n","    print(\"\\nStudent Job Recommendations:\")\n","    student_recommendations = df_with_recommendations[\n","        df_with_recommendations['DevType'] == 'Student'\n","    ][['RecommendedJobs', 'RecommendationConfidence']].head()\n","    \n","    for idx, row in student_recommendations.iterrows():\n","        print(f\"\\nStudent {idx + 1}\")\n","        for job, confidence in zip(row['RecommendedJobs'], row['RecommendationConfidence']):\n","            print(f\"- {job}: {confidence:.3f}\")"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T10:05:09.296017Z","iopub.status.busy":"2024-10-24T10:05:09.295610Z","iopub.status.idle":"2024-10-24T10:05:09.320065Z","shell.execute_reply":"2024-10-24T10:05:09.319214Z","shell.execute_reply.started":"2024-10-24T10:05:09.295979Z"},"trusted":true},"outputs":[{"data":{"text/plain":["RecommendedJobs\n","Developer, full-stack                            3720\n","Developer, back-end                              1351\n","Developer, front-end                               19\n","Developer, desktop or enterprise applications      10\n","Developer, embedded applications or devices         2\n","Name: count, dtype: int64"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["df_with_recommendations[df_with_recommendations['DevType']=='Student']['RecommendedJobs'].apply(lambda x: x[0]).value_counts()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5938550,"sourceId":9709169,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
